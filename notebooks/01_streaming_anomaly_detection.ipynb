{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentinel Stream â€” Streaming Anomaly Detection (Notebook)\n",
    "\n",
    "This notebook demonstrates an **industrial-grade streaming pipeline** for anomaly detection:\n",
    "\n",
    "- Synthetic event stream generation (security-ish telemetry)\n",
    "- Feature extraction in a rolling window\n",
    "- Online-style scoring (no lookahead)\n",
    "- Thresholding + alert summarization\n",
    "\n",
    "It is designed to be reproducible and easy to port into the `sentinel_stream/` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import deque\n",
    "from dataclasses import dataclass\n",
    "\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Generate a telemetry stream\n",
    "Each row is an aggregated event (per device, per minute). We inject anomalies: bursts, rare ports, entropy spikes." 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_devices = 50\n",
    "n_steps = 24 * 60  # 1 day at 1-min steps\n",
    "\n",
    "device_ids = [f'dev-{i:03d}' for i in range(n_devices)]\n",
    "\n",
    "rows = []\n",
    "for t in range(n_steps):\n",
    "    for dev in device_ids:\n",
    "        base_conn = rng.poisson(8)\n",
    "        base_bytes = max(0, rng.normal(80_000, 25_000))\n",
    "        # categorical-ish signals\n",
    "        port = int(rng.choice([22, 80, 443, 53, 445, 3389], p=[0.08, 0.25, 0.42, 0.18, 0.05, 0.02]))\n",
    "        entropy = float(np.clip(rng.normal(3.8, 0.4), 0.0, 8.0))\n",
    "\n",
    "        # inject anomalies (sparse)\n",
    "        is_anom = 0\n",
    "        if rng.random() < 0.0015:\n",
    "            # burst\n",
    "            base_conn += int(rng.integers(50, 150))\n",
    "            base_bytes *= float(rng.uniform(2.5, 6.0))\n",
    "            entropy = float(np.clip(entropy + rng.uniform(1.0, 2.5), 0.0, 8.0))\n",
    "            port = int(rng.choice([4444, 31337, 6667, 1337]))\n",
    "            is_anom = 1\n",
    "\n",
    "        rows.append((t, dev, base_conn, float(base_bytes), port, entropy, is_anom))\n",
    "\n",
    "df = pd.DataFrame(rows, columns=['t', 'device_id', 'connections', 'bytes', 'dst_port', 'payload_entropy', 'is_anom'])\n",
    "df.head(), df['is_anom'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Rolling feature extraction (no lookahead)" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RollingStats:\n",
    "    window: int\n",
    "    q: deque\n",
    "    sum_x: float = 0.0\n",
    "    sum_x2: float = 0.0\n",
    "\n",
    "    def push(self, x: float):\n",
    "        self.q.append(x)\n",
    "        self.sum_x += x\n",
    "        self.sum_x2 += x * x\n",
    "        if len(self.q) > self.window:\n",
    "            old = self.q.popleft()\n",
    "            self.sum_x -= old\n",
    "            self.sum_x2 -= old * old\n",
    "\n",
    "    def mean(self):\n",
    "        return self.sum_x / max(1, len(self.q))\n",
    "\n",
    "    def std(self):\n",
    "        n = len(self.q)\n",
    "        if n < 2:\n",
    "            return 0.0\n",
    "        mu = self.sum_x / n\n",
    "        var = max(0.0, (self.sum_x2 / n) - (mu * mu))\n",
    "        return float(np.sqrt(var))\n",
    "\n",
    "def zscore(x, mu, sigma):\n",
    "    return 0.0 if sigma <= 1e-9 else float((x - mu) / sigma)\n",
    "\n",
    "window = 60  # 60 minutes\n",
    "state = {dev: (RollingStats(window, deque()), RollingStats(window, deque()), RollingStats(window, deque())) for dev in device_ids}\n",
    "\n",
    "scores = []\n",
    "for row in df.itertuples(index=False):\n",
    "    t, dev, conns, bytes_, port, ent, is_anom = row\n",
    "    st_c, st_b, st_e = state[dev]\n",
    "\n",
    "    # compute score BEFORE update => no lookahead\n",
    "    zc = abs(zscore(conns, st_c.mean(), st_c.std()))\n",
    "    zb = abs(zscore(bytes_, st_b.mean(), st_b.std()))\n",
    "    ze = abs(zscore(ent, st_e.mean(), st_e.std()))\n",
    "\n",
    "    rare_port = 1.0 if port not in (22, 53, 80, 443, 445, 3389) else 0.0\n",
    "    score = 0.55 * zc + 0.35 * zb + 0.15 * ze + 2.0 * rare_port\n",
    "\n",
    "    scores.append((t, dev, score, is_anom))\n",
    "\n",
    "    # update window\n",
    "    st_c.push(float(conns))\n",
    "    st_b.push(float(bytes_))\n",
    "    st_e.push(float(ent))\n",
    "\n",
    "sc = pd.DataFrame(scores, columns=['t','device_id','score','is_anom'])\n",
    "sc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Alerting & evaluation" 
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick a threshold as a high quantile (unsupervised-ish)\n",
    "thr = sc['score'].quantile(0.999)\n",
    "sc['alert'] = (sc['score'] >= thr).astype(int)\n",
    "\n",
    "precision = (sc.query('alert==1 and is_anom==1').shape[0] / max(1, sc.query('alert==1').shape[0]))\n",
    "recall = (sc.query('alert==1 and is_anom==1').shape[0] / max(1, sc.query('is_anom==1').shape[0]))\n",
    "thr, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alerts = sc.query('alert==1').sort_values('score', ascending=False).head(15)\n",
    "alerts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
